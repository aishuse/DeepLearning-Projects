{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__BtLC1Y5hZW"
      },
      "source": [
        "-ANN mainly used for neumeric data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHXKkaefORPg",
        "outputId": "08c483fd-2eeb-4462-c11b-88c9c4fca9d7"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sI1K8_cTOq-7",
        "outputId": "cb46145e-ac1d-4e0c-af84-ae263b95d88d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
              "0      1            5.1           3.5            1.4           0.2   \n",
              "1      2            4.9           3.0            1.4           0.2   \n",
              "2      3            4.7           3.2            1.3           0.2   \n",
              "3      4            4.6           3.1            1.5           0.2   \n",
              "4      5            5.0           3.6            1.4           0.2   \n",
              "..   ...            ...           ...            ...           ...   \n",
              "145  146            6.7           3.0            5.2           2.3   \n",
              "146  147            6.3           2.5            5.0           1.9   \n",
              "147  148            6.5           3.0            5.2           2.0   \n",
              "148  149            6.2           3.4            5.4           2.3   \n",
              "149  150            5.9           3.0            5.1           1.8   \n",
              "\n",
              "            Species  \n",
              "0       Iris-setosa  \n",
              "1       Iris-setosa  \n",
              "2       Iris-setosa  \n",
              "3       Iris-setosa  \n",
              "4       Iris-setosa  \n",
              "..              ...  \n",
              "145  Iris-virginica  \n",
              "146  Iris-virginica  \n",
              "147  Iris-virginica  \n",
              "148  Iris-virginica  \n",
              "149  Iris-virginica  \n",
              "\n",
              "[150 rows x 6 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Iris.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "n-rrv5uNPOBg",
        "outputId": "8c24cd22-1e21-4059-9629-8059519fa35e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "0      1            5.1           3.5            1.4           0.2        0\n",
              "1      2            4.9           3.0            1.4           0.2        0\n",
              "2      3            4.7           3.2            1.3           0.2        0\n",
              "3      4            4.6           3.1            1.5           0.2        0\n",
              "4      5            5.0           3.6            1.4           0.2        0\n",
              "..   ...            ...           ...            ...           ...      ...\n",
              "145  146            6.7           3.0            5.2           2.3        2\n",
              "146  147            6.3           2.5            5.0           1.9        2\n",
              "147  148            6.5           3.0            5.2           2.0        2\n",
              "148  149            6.2           3.4            5.4           2.3        2\n",
              "149  150            5.9           3.0            5.1           1.8        2\n",
              "\n",
              "[150 rows x 6 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Species'] = le.fit_transform(df['Species'])\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-KO1G2FOyHW",
        "outputId": "1482268f-6256-452e-c970-5311a1f07049"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df.iloc[:,1:-1].values\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAkKRWgLOrAm",
        "outputId": "a08f1116-60cf-41cd-e5ca-4cc32aa16163"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "145    2\n",
              "146    2\n",
              "147    2\n",
              "148    2\n",
              "149    2\n",
              "Name: Species, Length: 150, dtype: int32"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df.iloc[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0yJF7ewPMeG",
        "outputId": "e1ebeddc-3139-4aea-af4e-0f11589d0bc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
              "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
              "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
              "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
              "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
              "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
              "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
              "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
              "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
              "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
              "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
              "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
              "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
              "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
              "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
              "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
              "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
              "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
              "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
              "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
              "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
              "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
              "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
              "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
              "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
              "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
              "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
              "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
              "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
              "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
              "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
              "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
              "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
              "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
              "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
              "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
              "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
              "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
              "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
              "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
              "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
              "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
              "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
              "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
              "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
              "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
              "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
              "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
              "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
              "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
              "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
              "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
              "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
              "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
              "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
              "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
              "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
              "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
              "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
              "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
              "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
              "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
              "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
              "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
              "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
              "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
              "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
              "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
              "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
              "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
              "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
              "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
              "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
              "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
              "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
              "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
              "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
              "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
              "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
              "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
              "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
              "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
              "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
              "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
              "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
              "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
              "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
              "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
              "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
              "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
              "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
              "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
              "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
              "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
              "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
              "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
              "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
              "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
              "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
              "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
              "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
              "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
              "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
              "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
              "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
              "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
              "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
              "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
              "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
              "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
              "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
              "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
              "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
              "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
              "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
              "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
              "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
              "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
              "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
              "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
              "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
              "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
              "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
              "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
              "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
              "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
              "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
              "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
              "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
              "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
              "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
              "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
              "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
              "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
              "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
              "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scalar = MinMaxScaler()\n",
        "X_scaled = scalar.fit_transform(X)\n",
        "X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T6BF59W2PMhL"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_scaled,y,test_size=0.3,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zo1nhS12PMpc"
      },
      "outputs": [],
      "source": [
        "# # here we need to get 3 kinds of o/p. so in o/p layer 3 neurons used. softmax activation fn is used. so highest probability is taken as ans\n",
        "\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# ann = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xpnDeVvGch3h"
      },
      "outputs": [],
      "source": [
        "# # input layer\n",
        "# ann.add(Dense(4,activation='relu'))    # units =4 bcoz 4 features\n",
        "\n",
        "# # 1st hidden layer\n",
        "# ann.add(Dense(4,activation='relu'))    # units =4\n",
        "\n",
        "# # 2nd hidden layer\n",
        "# ann.add(Dense(10,activation='relu'))    # units =4\n",
        "\n",
        "# # o/p layer . for binary classification dataset, 1 neuron is needed. we use sigmoid activation function\n",
        "\n",
        "# ann.add(Dense(3,activation='softmax'))    # for o/p layer either sigmoid/softmax is used\n",
        "# #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4g8jM0ltczqv"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "\n",
        "# ann.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])    # optimizer for updating weight , loss= diff of actual n predicted value, specify which metric performance to be improved by updating weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TESkZXBWczto"
      },
      "outputs": [],
      "source": [
        "# ann.fit(X_train,y_train, epochs=100, batch_size=10)  # epoch means how many times model shud learn, batch size is to split data for learning as batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcox7Z9RczwJ",
        "outputId": "99be0e3c-8b08-4905-d072-de9da5ec2aa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#error bcoz y is not in desired format.\n",
        "from keras.utils import to_categorical\n",
        "dummy_y = to_categorical(y)\n",
        "dummy_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b3LlsMETczy1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled,dummy_y,test_size=0.3,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jxQ9by8gcz1k"
      },
      "outputs": [],
      "source": [
        "# here we need to get 3 kinds of o/p. so in o/p layer 3 neurons used. softmax activation fn is used. so highest probability is taken as ans\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "ann = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9zhGbcdRjnNI"
      },
      "outputs": [],
      "source": [
        "# input layer\n",
        "ann.add(Dense(4,activation='relu'))    # units =4 bcoz 4 features\n",
        "\n",
        "# 1st hidden layer\n",
        "ann.add(Dense(4,activation='relu'))    # units =4\n",
        "\n",
        "# 2nd hidden layer\n",
        "ann.add(Dense(10,activation='relu'))    # units =4\n",
        "\n",
        "# o/p layer . for binary classification dataset, 1 neuron is needed. we use sigmoid activation function\n",
        "\n",
        "ann.add(Dense(3,activation='softmax'))    # for o/p layer either sigmoid/softmax is used\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5Gd1GGYfjnQH"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "\n",
        "ann.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])    # optimizer for updating weight , loss= diff of actual n predicted value, specify which metric performance to be improved by updating weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY46dHDTkPTo",
        "outputId": "bce52e2a-5ff8-4112-9ce4-57b34d01059a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2588 - loss: 1.1039\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3168 - loss: 1.0999 \n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3685 - loss: 1.0925 \n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3458 - loss: 1.0946 \n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3333 - loss: 1.0907  \n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3520 - loss: 1.0831 \n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3183 - loss: 1.0840 \n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3549 - loss: 1.0742 \n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3453 - loss: 1.0749 \n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3820 - loss: 1.0721 \n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4046 - loss: 1.0611 \n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4418 - loss: 1.0557 \n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4102 - loss: 1.0636 \n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5228 - loss: 1.0379 \n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4715 - loss: 1.0557 \n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5299 - loss: 1.0391 \n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 1.0100 \n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6326 - loss: 1.0130 \n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.9753 \n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6261 - loss: 1.0065 \n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6407 - loss: 0.9942 \n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6752 - loss: 0.9799 \n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6229 - loss: 0.9515 \n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6720 - loss: 0.9155 \n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7204 - loss: 0.9405 \n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 0.9074 \n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7076 - loss: 0.9031 \n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.8615 \n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 0.8664 \n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6993 - loss: 0.8451 \n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6632 - loss: 0.8626 \n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.7705 \n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6785 - loss: 0.8111 \n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7281 - loss: 0.7843 \n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.8217 \n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7599 - loss: 0.7242 \n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 0.7287 \n",
            "Epoch 38/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6670 - loss: 0.6988 \n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6449 - loss: 0.7840 \n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.7432 \n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.7158 \n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6981 - loss: 0.7297 \n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7187 - loss: 0.6795 \n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7047 - loss: 0.6710 \n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.6759 \n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6882 - loss: 0.6705  \n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.6952 \n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7193 - loss: 0.6572 \n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.6170 \n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 0.6822 \n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.6152 \n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7255 - loss: 0.6579 \n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6720 - loss: 0.6610 \n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7475 - loss: 0.6214 \n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6471 - loss: 0.6487 \n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6730 - loss: 0.6406 \n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.6338 \n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7120 - loss: 0.6375 \n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7232 - loss: 0.5964 \n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.6405 \n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.6240 \n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6761 - loss: 0.6476 \n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.6354 \n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.6215 \n",
            "Epoch 65/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7023 - loss: 0.6353 \n",
            "Epoch 66/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6785 - loss: 0.6137 \n",
            "Epoch 67/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 0.6278 \n",
            "Epoch 68/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6297 - loss: 0.6149 \n",
            "Epoch 69/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6979 - loss: 0.6167 \n",
            "Epoch 70/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6577 - loss: 0.6346 \n",
            "Epoch 71/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.6280 \n",
            "Epoch 72/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7334 - loss: 0.5918 \n",
            "Epoch 73/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7006 - loss: 0.6060 \n",
            "Epoch 74/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6726 - loss: 0.6559 \n",
            "Epoch 75/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6740 - loss: 0.5692 \n",
            "Epoch 76/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.6100 \n",
            "Epoch 77/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 0.5807 \n",
            "Epoch 78/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.5889 \n",
            "Epoch 79/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.5529 \n",
            "Epoch 80/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6993 - loss: 0.5395 \n",
            "Epoch 81/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.5617 \n",
            "Epoch 82/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7363 - loss: 0.5601 \n",
            "Epoch 83/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7343 - loss: 0.5177 \n",
            "Epoch 84/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6578 - loss: 0.6059 \n",
            "Epoch 85/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7189 - loss: 0.5508 \n",
            "Epoch 86/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.5712 \n",
            "Epoch 87/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.5220 \n",
            "Epoch 88/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6936 - loss: 0.5769 \n",
            "Epoch 89/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7022 - loss: 0.5724 \n",
            "Epoch 90/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 0.5547 \n",
            "Epoch 91/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6708 - loss: 0.5712 \n",
            "Epoch 92/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.5622 \n",
            "Epoch 93/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6993 - loss: 0.5783 \n",
            "Epoch 94/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7145 - loss: 0.5692 \n",
            "Epoch 95/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7306 - loss: 0.5282 \n",
            "Epoch 96/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6498 - loss: 0.5532 \n",
            "Epoch 97/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.5313 \n",
            "Epoch 98/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.5805 \n",
            "Epoch 99/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6754 - loss: 0.5518 \n",
            "Epoch 100/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.5806 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1565519ab50>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ann.fit(X_train,y_train, epochs=100, batch_size=10)  # epoch means how many times model shud learn, batch size is to split data for learning as batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q9vw1vvkPW_",
        "outputId": "d3f7fb6e-871a-4b7e-af7d-c2fe4845421f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m20\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m20\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m50\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">371</span> (1.45 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m371\u001b[0m (1.45 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123</span> (492.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123\u001b[0m (492.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248</span> (996.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m248\u001b[0m (996.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ann.summary()    # 4 is no: of i/p, 5 is no: of neurons(4 + 1 bias). 4*5 =20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tu0tdANkPZ6",
        "outputId": "093629f1-cd95-4f57-8c36-19e191a9b315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5875 - loss: 0.5867 \n",
            "loss  0.5933108329772949\n",
            "accuracy  0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "loss,accuracy = ann.evaluate(X_test,y_test)\n",
        "print('loss ',loss)\n",
        "print('accuracy ',accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPtkYIgrkPcv",
        "outputId": "af6eb25f-76bf-4495-ae74-9aa5ea44cb61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[9.9875605e-01, 8.5650949e-04, 3.8745810e-04]], dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_new = ann.predict(scalar.transform([[5.1,3.5,1.4,.2]]))\n",
        "y_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvPaD5PHrmVh",
        "outputId": "58922633-df03-4276-b9b4-e3d375c78b7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loc to find max value in y_new\n",
        "\n",
        "ind = y_new.argmax(axis=1)\n",
        "ind.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "weQ1gvwzsMJI",
        "outputId": "d5697950-ff82-4a38-fc33-7bbf383e5799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Iris-setosa'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls = le.inverse_transform(ind)\n",
        "cls.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQabkgLdt0Sb",
        "outputId": "9c9c2b8e-21d5-4964-8592-9472b4e0650e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aViJTprvt0_x",
        "outputId": "4e30a013-eb34-4055-9e9d-822a2d467233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[9.9980277e-01, 1.4449908e-04, 5.2836342e-05],\n",
              "       [1.4850636e-01, 4.0053636e-01, 4.5095727e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9946195e-01, 3.8169161e-04, 1.5637696e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.5083309e-01, 4.0191767e-01, 4.4724926e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9884439e-01, 8.0026238e-04, 3.5529691e-04],\n",
              "       [9.9594092e-01, 2.6746707e-03, 1.3845154e-03],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9924964e-01, 5.2729284e-04, 2.2294495e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.5075177e-01, 4.0187004e-01, 4.4737822e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9717391e-01, 1.8873318e-03, 9.3870098e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9538273e-01, 3.0355300e-03, 1.5817366e-03],\n",
              "       [9.9666166e-01, 2.2156134e-03, 1.1227893e-03],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9844462e-01, 1.0620620e-03, 4.9335911e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9990714e-01, 6.9505229e-05, 2.3320605e-05],\n",
              "       [9.9941599e-01, 4.1301284e-04, 1.7099304e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9933261e-01, 4.7001117e-04, 1.9743128e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9806780e-01, 1.3100094e-03, 6.2230398e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [9.9823415e-01, 1.2011324e-03, 5.6460145e-04],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01],\n",
              "       [1.4234987e-01, 3.9668852e-01, 4.6096161e-01]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN5DaZ0qt1Da",
        "outputId": "ba10e11d-45be-4c25-ecdc-0ed05a6a02fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2,\n",
              "       2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2,\n",
              "       2], dtype=int64)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ypred = y_pred.argmax(axis=1)\n",
        "ypred # to generate classification report, index of y_pred taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNp9EzjVt1G9",
        "outputId": "710e2211-fc3e-4b29-ff24-0ee509c29dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2,\n",
              "       1], dtype=int64)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ytest = y_test.argmax(axis=1)\n",
        "ytest # to generate classification report, index of y_test taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYGw4m0oxJut",
        "outputId": "5ea9c78c-0e2a-4346-d60a-10a6b7a23949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       0.00      0.00      0.00        18\n",
            "           2       0.42      1.00      0.59        13\n",
            "\n",
            "    accuracy                           0.60        45\n",
            "   macro avg       0.47      0.67      0.53        45\n",
            "weighted avg       0.43      0.60      0.48        45\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aiswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\aiswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\aiswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest,ypred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
