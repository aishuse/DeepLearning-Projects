{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP0RHpZJA_hK",
        "outputId": "252fb62b-b609-46bb-e35f-55d4594bc9a9"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LM6Yt--cBf27",
        "outputId": "74ae521d-97f6-429d-90a6-469860ce7c80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00             1.9      0.076   \n",
              "1               7.8             0.880         0.00             2.6      0.098   \n",
              "2               7.8             0.760         0.04             2.3      0.092   \n",
              "3              11.2             0.280         0.56             1.9      0.075   \n",
              "4               7.4             0.700         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "1594            6.2             0.600         0.08             2.0      0.090   \n",
              "1595            5.9             0.550         0.10             2.2      0.062   \n",
              "1596            6.3             0.510         0.13             2.3      0.076   \n",
              "1597            5.9             0.645         0.12             2.0      0.075   \n",
              "1598            6.0             0.310         0.47             3.6      0.067   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
              "\n",
              "      alcohol  quality  \n",
              "0         9.4        5  \n",
              "1         9.8        5  \n",
              "2         9.8        5  \n",
              "3         9.8        6  \n",
              "4         9.4        5  \n",
              "...       ...      ...  \n",
              "1594     10.5        5  \n",
              "1595     11.2        6  \n",
              "1596     11.0        6  \n",
              "1597     10.2        5  \n",
              "1598     11.0        6  \n",
              "\n",
              "[1599 rows x 12 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('winequality-red.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQTtxw9mByBm",
        "outputId": "0f7063ab-1c26-4a7f-f342-2f4ef59cbfbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fixed acidity           0\n",
              "volatile acidity        0\n",
              "citric acid             0\n",
              "residual sugar          0\n",
              "chlorides               0\n",
              "free sulfur dioxide     0\n",
              "total sulfur dioxide    0\n",
              "density                 0\n",
              "pH                      0\n",
              "sulphates               0\n",
              "alcohol                 0\n",
              "quality                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xgNSB5FByEN",
        "outputId": "cd4497fc-bf43-4ba4-dc15-5a67e8524ef6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fixed acidity           float64\n",
              "volatile acidity        float64\n",
              "citric acid             float64\n",
              "residual sugar          float64\n",
              "chlorides               float64\n",
              "free sulfur dioxide     float64\n",
              "total sulfur dioxide    float64\n",
              "density                 float64\n",
              "pH                      float64\n",
              "sulphates               float64\n",
              "alcohol                 float64\n",
              "quality                   int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpgL0Si1ByG4",
        "outputId": "dca22526-0dce-4689-a34f-250f899a27cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "quality\n",
              "5    681\n",
              "6    638\n",
              "7    199\n",
              "4     53\n",
              "8     18\n",
              "3     10\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['quality'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd8DIgFsByJJ",
        "outputId": "163ac056-8e41-4609-899a-d3e66b162ae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],\n",
              "       [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],\n",
              "       [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],\n",
              "       ...,\n",
              "       [ 6.3  ,  0.51 ,  0.13 , ...,  3.42 ,  0.75 , 11.   ],\n",
              "       [ 5.9  ,  0.645,  0.12 , ...,  3.57 ,  0.71 , 10.2  ],\n",
              "       [ 6.   ,  0.31 ,  0.47 , ...,  3.39 ,  0.66 , 11.   ]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df.iloc[:,:-1].values\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZhrdccCByLx",
        "outputId": "f2034f48-aa37-46ef-a842-155e4305f278"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       5\n",
              "1       5\n",
              "2       5\n",
              "3       6\n",
              "4       5\n",
              "       ..\n",
              "1594    5\n",
              "1595    6\n",
              "1596    6\n",
              "1597    5\n",
              "1598    6\n",
              "Name: quality, Length: 1599, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df.iloc[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCYoBwpzByOB",
        "outputId": "e127a10b-40bd-4940-989b-fd36e6e844cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 3, 2, 3], dtype=int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#3    -> 0\n",
        "#4    1\n",
        "#5    2\n",
        "#6     3\n",
        "#7     4\n",
        "#8     5                                #is the wine quality. label encode it\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "encoded_y = le.fit_transform(y)\n",
        "\n",
        "encoded_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQJflatcByQh",
        "outputId": "a4d057bc-c6ca-4a54-a25f-2b4c516255b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert 0 in y to 1 0 0 0 0 0\n",
        "#         1         0 1 0 0 0 0 etc\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_cat = to_categorical(encoded_y)\n",
        "y_cat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "00lSO-lrByS0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y_cat,test_size=0.3,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DLV1gZi_ByVm"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BY1P8OC7EIPW"
      },
      "outputs": [],
      "source": [
        "# input layer\n",
        "model.add(Dense(11,activation='relu'))    # units =11 bcoz 11 features\n",
        "\n",
        "# 1st hidden layer\n",
        "model.add(Dense(10,activation='relu'))\n",
        "\n",
        "# 2nd hidden layer\n",
        "model.add(Dense(20,activation='relu'))\n",
        "\n",
        "# o/p layer . for binary classification dataset, 1 neuron is needed. we use sigmoid activation function\n",
        "\n",
        "model.add(Dense(6,activation='softmax'))    # for o/p layer either sigmoid/softmax is used\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6RHT_gNuEIQ1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])    # optimizer for updating weight , loss= diff of actual n predicted value, specify which metric performance to be improved by updating weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZvWXG3cEIUR",
        "outputId": "863fc6ed-ef99-49c7-fadc-09dfa3da26dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3862 - loss: 4.7022\n",
            "Epoch 2/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4762 - loss: 1.2989\n",
            "Epoch 3/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4923 - loss: 1.3083\n",
            "Epoch 4/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5019 - loss: 1.2293\n",
            "Epoch 5/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4914 - loss: 1.1731\n",
            "Epoch 6/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4950 - loss: 1.1114\n",
            "Epoch 7/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4950 - loss: 1.1328\n",
            "Epoch 8/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5490 - loss: 1.1225\n",
            "Epoch 9/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4731 - loss: 1.1937\n",
            "Epoch 10/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4886 - loss: 1.1620\n",
            "Epoch 11/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 1.1436\n",
            "Epoch 12/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5226 - loss: 1.1280\n",
            "Epoch 13/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4922 - loss: 1.1402\n",
            "Epoch 14/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5201 - loss: 1.1369\n",
            "Epoch 15/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5056 - loss: 1.1368\n",
            "Epoch 16/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4985 - loss: 1.1514\n",
            "Epoch 17/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 1.1099\n",
            "Epoch 18/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: 1.1497\n",
            "Epoch 19/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: 1.1226\n",
            "Epoch 20/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5053 - loss: 1.1429\n",
            "Epoch 21/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5069 - loss: 1.1413\n",
            "Epoch 22/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4910 - loss: 1.1214\n",
            "Epoch 23/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5184 - loss: 1.0895\n",
            "Epoch 24/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 1.1155\n",
            "Epoch 25/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5107 - loss: 1.1062\n",
            "Epoch 26/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5266 - loss: 1.1043\n",
            "Epoch 27/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 1.0585\n",
            "Epoch 28/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5416 - loss: 1.0866\n",
            "Epoch 29/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5215 - loss: 1.1101\n",
            "Epoch 30/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5174 - loss: 1.0881\n",
            "Epoch 31/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5636 - loss: 1.0652\n",
            "Epoch 32/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5130 - loss: 1.0593\n",
            "Epoch 33/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5222 - loss: 1.0665\n",
            "Epoch 34/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5420 - loss: 1.0799\n",
            "Epoch 35/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5259 - loss: 1.0411\n",
            "Epoch 36/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 1.0208\n",
            "Epoch 37/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5364 - loss: 1.0242\n",
            "Epoch 38/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5449 - loss: 1.0826\n",
            "Epoch 39/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5074 - loss: 1.0659\n",
            "Epoch 40/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5151 - loss: 1.0591\n",
            "Epoch 41/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 1.0909\n",
            "Epoch 42/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5425 - loss: 1.0114\n",
            "Epoch 43/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5605 - loss: 0.9873\n",
            "Epoch 44/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5559 - loss: 0.9964\n",
            "Epoch 45/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5584 - loss: 0.9936\n",
            "Epoch 46/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5514 - loss: 1.0099\n",
            "Epoch 47/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5866 - loss: 0.9847\n",
            "Epoch 48/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5548 - loss: 1.0160\n",
            "Epoch 49/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5536 - loss: 1.0238\n",
            "Epoch 50/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5631 - loss: 0.9861\n",
            "Epoch 51/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5490 - loss: 1.0016\n",
            "Epoch 52/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5497 - loss: 0.9851\n",
            "Epoch 53/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.9448\n",
            "Epoch 54/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5573 - loss: 0.9659\n",
            "Epoch 55/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5465 - loss: 1.0045\n",
            "Epoch 56/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5617 - loss: 0.9537\n",
            "Epoch 57/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5395 - loss: 0.9934\n",
            "Epoch 58/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.9541\n",
            "Epoch 59/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5521 - loss: 1.0058\n",
            "Epoch 60/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5562 - loss: 0.9882\n",
            "Epoch 61/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5902 - loss: 0.9397\n",
            "Epoch 62/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5668 - loss: 0.9412\n",
            "Epoch 63/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5604 - loss: 1.0041\n",
            "Epoch 64/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.9639\n",
            "Epoch 65/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.9432\n",
            "Epoch 66/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6024 - loss: 0.9107\n",
            "Epoch 67/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 0.9345\n",
            "Epoch 68/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5654 - loss: 0.9756\n",
            "Epoch 69/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5348 - loss: 0.9858\n",
            "Epoch 70/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5602 - loss: 0.9668\n",
            "Epoch 71/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 0.9324\n",
            "Epoch 72/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5895 - loss: 0.9336\n",
            "Epoch 73/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5201 - loss: 0.9662\n",
            "Epoch 74/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5507 - loss: 0.9855\n",
            "Epoch 75/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.9238\n",
            "Epoch 76/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 0.9490\n",
            "Epoch 77/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5707 - loss: 0.9499\n",
            "Epoch 78/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.9725\n",
            "Epoch 79/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 0.9242\n",
            "Epoch 80/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 0.9404\n",
            "Epoch 81/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.9440\n",
            "Epoch 82/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.9235\n",
            "Epoch 83/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.9408\n",
            "Epoch 84/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5830 - loss: 0.9439\n",
            "Epoch 85/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5705 - loss: 0.9155\n",
            "Epoch 86/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.9322\n",
            "Epoch 87/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.9309\n",
            "Epoch 88/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5744 - loss: 0.9539\n",
            "Epoch 89/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 0.9273\n",
            "Epoch 90/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5949 - loss: 0.9332\n",
            "Epoch 91/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.9204\n",
            "Epoch 92/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 0.9024\n",
            "Epoch 93/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.9576\n",
            "Epoch 94/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5870 - loss: 0.9364\n",
            "Epoch 95/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5674 - loss: 0.9455\n",
            "Epoch 96/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.9358\n",
            "Epoch 97/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.9500\n",
            "Epoch 98/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6182 - loss: 0.8714\n",
            "Epoch 99/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5837 - loss: 0.9370\n",
            "Epoch 100/100\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 0.9789\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x18cff0cea90>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train,y_train, epochs=100, batch_size=10)  # epoch means how many times model shud learn, batch size is to split data for learning as batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5RgaPCJEIX5",
        "outputId": "3257dd17-21f7-4557-cb34-b6196af908e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m132\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m126\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,796</span> (7.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,796\u001b[0m (7.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598</span> (2.34 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m598\u001b[0m (2.34 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,198</span> (4.68 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,198\u001b[0m (4.68 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()    # 4 is no: of i/p, 5 is no: of neurons(4 + 1 bias). 4*5 =20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vS--ci3E-sv"
      },
      "source": [
        "binary clasification problems can be handled using softmax algm, convert y to categorical data. change 0 to 0 0,        1 to 0 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eSZILSKgEIa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.0623942e-03, 1.0919070e-02, 4.2495859e-01, 5.1750851e-01,\n",
              "        4.3757923e-02, 1.7935871e-03],\n",
              "       [1.4470408e-03, 1.1712377e-02, 6.3338923e-01, 3.4137893e-01,\n",
              "        1.1729378e-02, 3.4307421e-04],\n",
              "       [4.8339478e-04, 8.9587886e-03, 1.5149195e-01, 4.7487974e-01,\n",
              "        3.3367556e-01, 3.0510627e-02],\n",
              "       ...,\n",
              "       [4.1273944e-02, 9.4675966e-02, 6.3683432e-01, 2.1927899e-01,\n",
              "        7.5912741e-03, 3.4547932e-04],\n",
              "       [1.2809162e-03, 1.7409757e-02, 3.9869326e-01, 5.4567379e-01,\n",
              "        3.5519708e-02, 1.4225884e-03],\n",
              "       [2.1657711e-03, 2.6595186e-02, 2.5960791e-01, 5.0917935e-01,\n",
              "        1.8335244e-01, 1.9099388e-02]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgTEjX-GEIdp",
        "outputId": "174d3eef-648f-4407-c39b-55538c15c946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6486 - loss: 0.8511  \n",
            "loss  0.940759539604187\n",
            "accuracy  0.6291666626930237\n"
          ]
        }
      ],
      "source": [
        "loss,accuracy = model.evaluate(X_test,y_test)\n",
        "print('loss ',loss)\n",
        "print('accuracy ',accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTgdSRNCEIg0",
        "outputId": "e0ccebd9-fba3-4b66-fc90-29bdcd732202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "[[1.2262860e-02 4.4680621e-02 7.0494878e-01 2.3584326e-01 2.2205943e-03\n",
            "  4.3880391e-05]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Input data as a NumPy array\n",
        "x_new = np.array([[7.4, 0.700, 0.00, 1.9, 0.076, 11.0, 34.0, 0.99780, 3.51, 0.56, 9.4]])\n",
        "\n",
        "# Predict using the model\n",
        "y_new = model.predict(x_new)\n",
        "print(y_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVVfuGiEEIh_",
        "outputId": "54e9ca4c-1bc2-42aa-b76a-8e1b63b47d1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loc to find max value in y_new\n",
        "\n",
        "ind = y_new.argmax(axis=1)\n",
        "ind.item()  # returns index value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1burpkZHEIjM",
        "outputId": "34b2214c-5e89-4cfc-adf9-9c6a19424053"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls = le.inverse_transform(ind)\n",
        "cls.item()   # quality 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m30XWs3kEImV",
        "outputId": "85b439d7-c994-4c7f-c6e4-c21f48c8e3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.0623942e-03, 1.0919070e-02, 4.2495859e-01, 5.1750851e-01,\n",
              "        4.3757923e-02, 1.7935871e-03],\n",
              "       [1.4470408e-03, 1.1712377e-02, 6.3338923e-01, 3.4137893e-01,\n",
              "        1.1729378e-02, 3.4307421e-04],\n",
              "       [4.8339478e-04, 8.9587886e-03, 1.5149195e-01, 4.7487974e-01,\n",
              "        3.3367556e-01, 3.0510627e-02],\n",
              "       ...,\n",
              "       [4.1273944e-02, 9.4675966e-02, 6.3683432e-01, 2.1927899e-01,\n",
              "        7.5912741e-03, 3.4547932e-04],\n",
              "       [1.2809162e-03, 1.7409757e-02, 3.9869326e-01, 5.4567379e-01,\n",
              "        3.5519708e-02, 1.4225884e-03],\n",
              "       [2.1657711e-03, 2.6595186e-02, 2.5960791e-01, 5.0917935e-01,\n",
              "        1.8335244e-01, 1.9099388e-02]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5QkG_5uHtJT",
        "outputId": "111097bb-3709-4a5b-a095-2879867c1c2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x3UuHrRHvTC"
      },
      "source": [
        "y_test and y_pred cant be compared, so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3GjN6jjH78v",
        "outputId": "641742c7-8c59-424c-91e2-8c5dde0ca8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([3, 2, 3, 3, 4, 3, 3, 2, 3, 2, 3, 2, 2, 4, 3, 2, 3, 2, 3, 2, 3, 3,\n",
              "       2, 3, 2, 3, 3, 3, 2, 2, 2, 4, 2, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3,\n",
              "       2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2,\n",
              "       4, 2, 3, 4, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3,\n",
              "       2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2,\n",
              "       4, 2, 3, 3, 2, 4, 2, 2, 2, 2, 2, 4, 3, 2, 2, 3, 3, 2, 3, 3, 3, 2,\n",
              "       3, 2, 3, 3, 2, 4, 2, 2, 2, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 2, 2,\n",
              "       3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 4, 2,\n",
              "       2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2,\n",
              "       3, 2, 3, 3, 3, 2, 4, 3, 2, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2,\n",
              "       3, 3, 2, 2, 3, 3, 2, 3, 4, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3,\n",
              "       3, 2, 3, 4, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2,\n",
              "       2, 3, 3, 2, 2, 3, 2, 3, 2, 4, 2, 3, 2, 3, 2, 2, 4, 2, 3, 2, 2, 3,\n",
              "       2, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 3, 2, 3,\n",
              "       3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 3, 2, 2, 2, 2, 4, 3, 2,\n",
              "       2, 2, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 2, 3, 2, 4, 3, 2, 2, 2, 3, 4,\n",
              "       2, 3, 3, 2, 4, 4, 2, 2, 2, 3, 2, 4, 2, 2, 2, 2, 3, 2, 3, 3, 2, 2,\n",
              "       2, 3, 4, 4, 2, 3, 3, 3, 3, 3, 3, 4, 2, 3, 3, 3, 2, 2, 2, 3, 2, 3,\n",
              "       2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3,\n",
              "       3, 2, 2, 3, 3, 3, 2, 3, 4, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3,\n",
              "       3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2,\n",
              "       2, 3, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3], dtype=int64)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iRXHYZHH8DE",
        "outputId": "99b52543-f160-47f5-d866-3d9aa8710c12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3,\n",
              "       2, 3, 3, 3, 3, 3, 3, 4, 3, 3, 2, 3, 2, 3, 2, 4, 3, 2, 3, 2, 2, 3,\n",
              "       2, 3, 2, 2, 2, 3, 2, 1, 4, 2, 2, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3,\n",
              "       4, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 4,\n",
              "       2, 3, 2, 4, 2, 3, 2, 2, 3, 2, 0, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3,\n",
              "       4, 2, 3, 3, 2, 4, 2, 2, 2, 2, 1, 4, 4, 2, 2, 2, 3, 2, 4, 4, 3, 2,\n",
              "       4, 2, 3, 4, 2, 4, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3,\n",
              "       2, 4, 2, 3, 3, 3, 5, 3, 2, 2, 3, 3, 1, 2, 2, 3, 3, 3, 1, 4, 2, 3,\n",
              "       2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 4, 3, 1, 3, 2, 3, 3, 2, 3, 2, 1, 2,\n",
              "       3, 2, 4, 2, 4, 2, 4, 3, 2, 2, 3, 2, 2, 4, 2, 3, 2, 3, 2, 2, 4, 3,\n",
              "       2, 3, 2, 2, 3, 2, 1, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 2, 1, 3, 2,\n",
              "       4, 3, 3, 5, 3, 2, 2, 2, 2, 1, 3, 3, 3, 2, 2, 1, 2, 2, 3, 2, 2, 2,\n",
              "       1, 3, 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 1, 1, 2, 3, 2,\n",
              "       3, 2, 2, 2, 3, 3, 3, 2, 3, 4, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2,\n",
              "       2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 4, 3, 3, 2, 3, 2, 2, 2, 2, 4, 2, 3,\n",
              "       4, 3, 2, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 2, 4, 4, 2, 1, 2, 4, 4,\n",
              "       2, 1, 3, 1, 4, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2,\n",
              "       2, 3, 4, 5, 3, 3, 3, 3, 4, 2, 3, 4, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2,\n",
              "       2, 4, 2, 4, 2, 1, 2, 2, 1, 1, 3, 4, 2, 4, 3, 2, 2, 2, 2, 2, 2, 3,\n",
              "       3, 3, 4, 3, 4, 3, 3, 2, 4, 2, 0, 3, 2, 2, 2, 2, 2, 2, 4, 2, 3, 3,\n",
              "       2, 4, 3, 4, 2, 2, 2, 2, 3, 2, 2, 1, 3, 2, 3, 2, 3, 1, 4, 2, 2, 2,\n",
              "       2, 3, 2, 3, 3, 3, 3, 4, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3], dtype=int64)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUl2og1WH8Fa",
        "outputId": "addf9fae-15d4-4f0b-c7d4-35db8356cbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00        21\n",
            "           2       0.66      0.77      0.71       207\n",
            "           3       0.60      0.66      0.63       195\n",
            "           4       0.56      0.27      0.36        52\n",
            "           5       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.63       480\n",
            "   macro avg       0.30      0.28      0.28       480\n",
            "weighted avg       0.59      0.63      0.60       480\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aiswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\aiswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\aiswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test.argmax(axis=1),y_pred.argmax(axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UzvBavvH8IV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
